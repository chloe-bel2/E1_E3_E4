name: CI Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      # Vérification du code source
      - name: Check out code
        uses: actions/checkout@v2

      # Configuration de Python
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      # Étape 3 : Mise en cache des dépendances Python
      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      # Installation des dépendances
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Étape 5 : Pull des images Docker existantes
      - name: Pull Docker images
        run: |
          docker-compose -f docker-compose.yml pull  # Récupérer les images existantes

      - name: Start services with Docker Compose
        run: |
          docker-compose -f docker-compose.yml up -d
        
        # Attente que PostgreSQL soit prêt
      - name: Wait for PostgreSQL to be ready
        run: |
          for i in {1..30}; do
            pg_isready -h postgres -p 5432 && break || echo "Waiting for PostgreSQL...";
            sleep 5;
          done
      
      # Importation du schéma de base de données
      - name: Import database schema
        run: | 
          docker exec $(docker ps -q -f name=postgres) psql -U postgres -d db_pco < .github/workflows/db_pco_schema.sql
        env:
          PGPASSWORD: postgre
      
      # Arrêter les services Docker Compose
      - name: Stop services with Docker Compose
        run: |
          docker-compose -f docker-compose.yml down
